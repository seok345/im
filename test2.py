import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import cv2
import numpy as np
import os
import glob
from matplotlib import pyplot as plt
from tqdm import tqdm  # ÌïôÏäµ ÏßÑÌñâÎ•† ÌëúÏãú ÎùºÏù¥Î∏åÎü¨Î¶¨


# --- 1. U-Net Architecture Definition (Î™®Îç∏ Íµ¨Ï°∞) ---
# (Ïù¥ Î∂ÄÎ∂ÑÏùÄ ÎèôÏùºÌï©ÎãàÎã§.)

class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(DoubleConv, self).__init__()
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.double_conv(x)


class UNet(nn.Module):
    def __init__(self, n_channels=1, n_classes=3):
        super(UNet, self).__init__()
        self.inc = DoubleConv(n_channels, 64)
        self.down1 = nn.MaxPool2d(2);
        self.conv1 = DoubleConv(64, 128)
        self.down2 = nn.MaxPool2d(2);
        self.conv2 = DoubleConv(128, 256)
        self.down3 = nn.MaxPool2d(2);
        self.conv3 = DoubleConv(256, 512)
        self.down4 = nn.MaxPool2d(2);
        self.conv4 = DoubleConv(512, 1024)

        self.up1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)
        self.up_conv1 = DoubleConv(1024, 512)
        self.up2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)
        self.up_conv2 = DoubleConv(512, 256)
        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.up_conv3 = DoubleConv(256, 128)
        self.up4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.up_conv4 = DoubleConv(128, 64)

        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.down1(x1);
        x2 = self.conv1(x2)
        x3 = self.down2(x2);
        x3 = self.conv2(x3)
        x4 = self.down3(x3);
        x4 = self.conv3(x4)
        x5 = self.down4(x4);
        x5 = self.conv4(x5)

        x = self.up1(x5);
        x = torch.cat([x, x4], dim=1);
        x = self.up_conv1(x)
        x = self.up2(x);
        x = torch.cat([x, x3], dim=1);
        x = self.up_conv2(x)
        x = self.up3(x);
        x = torch.cat([x, x2], dim=1);
        x = self.up_conv3(x)
        x = self.up4(x);
        x = torch.cat([x, x1], dim=1);
        x = self.up_conv4(x)

        return self.outc(x)


# --- 2. Custom Dataset Class ---
# (Ïù¥ Î∂ÄÎ∂ÑÏùÄ ÎèôÏùºÌï©ÎãàÎã§.)
class ColorizationDataset(Dataset):
    def __init__(self, color_dir, grayscale_dir, image_size=256):
        self.color_dir = color_dir
        self.grayscale_dir = grayscale_dir
        self.image_size = image_size

        self.filenames = [os.path.basename(f) for f in glob.glob(os.path.join(color_dir, '*.jpg'))]

        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize((image_size, image_size), antialias=True)
        ])

    def __len__(self):
        return len(self.filenames)

    def __getitem__(self, idx):
        filename = self.filenames[idx]

        grayscale_path = os.path.join(self.grayscale_dir, filename)
        input_img = cv2.imread(grayscale_path, cv2.IMREAD_GRAYSCALE)

        color_path = os.path.join(self.color_dir, filename)
        target_img = cv2.imread(color_path, cv2.IMREAD_COLOR)

        if input_img is None or target_img is None:
            raise RuntimeError(f"Ïù¥ÎØ∏ÏßÄ Î°úÎìú Ïã§Ìå®. ÌååÏùºÏù¥ Îëê Ìè¥Îçî Î™®ÎëêÏóê ÏûàÎäîÏßÄ ÌôïÏù∏: {filename}")

        target_img = cv2.cvtColor(target_img, cv2.COLOR_BGR2RGB)

        input_tensor = self.transform(input_img).float()
        target_tensor = self.transform(target_img).float()

        return input_tensor, target_tensor


# --- 3. Training and Prediction Function (ÏàòÏ†ïÎêú Î∂ÄÎ∂Ñ: Ïù¥Ïñ¥ÏÑú ÌïôÏäµ Í∏∞Îä• Ï∂îÍ∞Ä) ---

def train_and_predict_colorization(color_dir, grayscale_dir, model_save_path='./colorization_unet.pth'):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ÏÇ¨Ïö© Ïû•Ïπò: {device}")

    # Hyperparameters
    # ‚≠ê Ìïú Î≤àÏóê ÌïôÏäµÌï† ÏóêÌè¨ÌÅ¨ ÏàòÎ•º Ï†ÅÍ≤å ÏÑ§Ï†ï (ÏõêÌïòÎäî ÎßåÌÅº ÏàòÏ†ï Í∞ÄÎä•)
    EPOCHS_TO_RUN = 5

    learning_rate = 0.0005
    batch_size = 4
    image_size = 256

    # Data Loading
    print("\nüì¶ Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎî© Ï§ë...")
    dataset = ColorizationDataset(color_dir, grayscale_dir, image_size)

    if len(dataset) == 0:
        print("\nüö® Ïò§Î•ò: ÌïôÏäµÌï† Ïù¥ÎØ∏ÏßÄÍ∞Ä ÏóÜÏäµÎãàÎã§. Îëê Ìè¥ÎçîÏóê Ïù¥ÎØ∏ÏßÄÍ∞Ä ÏûàÎäîÏßÄ ÌôïÏù∏ÌïòÏÑ∏Ïöî.")
        return

    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
    num_batches = len(dataloader)

    # Model, Loss, Optimizer
    model = UNet(n_channels=1, n_classes=3).to(device)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    # ‚≠ê Î™®Îç∏ Î°úÎìú Î°úÏßÅ Ï∂îÍ∞Ä: ÌååÏùºÏù¥ ÏûàÏúºÎ©¥ Ïù¥Ïñ¥ÏÑú ÌïôÏäµ
    if os.path.exists(model_save_path):
        print(f"‚úîÔ∏è Í∏∞Ï°¥ Î™®Îç∏ '{model_save_path}'ÏùÑ(Î•º) Î∂àÎü¨ÏôÄ Ïù¥Ïñ¥ÏÑú ÌïôÏäµÌï©ÎãàÎã§.")
        model.load_state_dict(torch.load(model_save_path, map_location=device))
    else:
        print(f"‚ú® ÏÉàÎ°úÏö¥ ÌïôÏäµÏùÑ ÏãúÏûëÌï©ÎãàÎã§. Î™®Îç∏ÏùÄ '{model_save_path}'Ïóê Ï†ÄÏû•Îê©ÎãàÎã§.")

    # --- Training Loop ---
    print(f"\n--- Î™®Îç∏ ÌïôÏäµ ÏãúÏûë (Ïù¥Î≤àÏóê {EPOCHS_TO_RUN} ÏóêÌè¨ÌÅ¨ ÏßÑÌñâ) ---")
    model.train()

    # Ï†ÑÏ≤¥ ÌïôÏäµ ÏóêÌè¨ÌÅ¨Îäî Î¨¥ÌïúÎåÄÎ°ú ÏÑ§Ï†ïÌïòÍ≥†, Ïã§Ï†ú Ïã§Ìñâ ÌöüÏàòÎ•º EPOCHS_TO_RUNÏúºÎ°ú Ï†úÌïúÌï©ÎãàÎã§.
    for epoch in range(EPOCHS_TO_RUN):

        progress_bar = tqdm(enumerate(dataloader), total=num_batches,
                            desc=f"Epoch {epoch + 1}/{EPOCHS_TO_RUN}", unit="batch")

        running_loss = 0.0

        for i, (inputs, targets) in progress_bar:
            inputs, targets = inputs.to(device), targets.to(device)

            outputs = model(inputs)
            loss = criterion(outputs, targets)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

            # ÏßÑÌñâÎ•† ÌëúÏãúÏ§ÑÏóê ÌòÑÏû¨ Î∞∞Ïπò ÏÜêÏã§(Loss) Í∞í ÏóÖÎç∞Ïù¥Ìä∏
            progress_bar.set_postfix({'Loss': loss.item()})

        avg_epoch_loss = running_loss / num_batches
        print(f"\n[Epoch {epoch + 1} ÏôÑÎ£å] üåü ÌèâÍ∑† ÏÜêÏã§(Avg Loss): {avg_epoch_loss:.6f}")

    # ‚≠ê Îß§Î≤à ÌïôÏäµÏù¥ ÎÅùÎÇ† ÎïåÎßàÎã§ Î™®Îç∏ Ï†ÄÏû•
    print(f"\n‚úÖ {EPOCHS_TO_RUN} ÏóêÌè¨ÌÅ¨ ÌïôÏäµ ÏôÑÎ£å. Î™®Îç∏ Ï†ÄÏû• Ï§ë...")
    torch.save(model.state_dict(), model_save_path)
    print(f"Î™®Îç∏Ïù¥ '{model_save_path}'Ïóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§. Îã§Ïãú Ïã§ÌñâÌïòÎ©¥ Ïù¥Ïñ¥ÏÑú ÌïôÏäµÎê©ÎãàÎã§.")

    # --- Prediction Example (ÌÖåÏä§Ìä∏ Î∂ÄÎ∂Ñ) ---
    print("\n--- ÌïôÏäµÎêú Î™®Îç∏Î°ú ÌÖåÏä§Ìä∏ (Í≤∞Í≥º ÏãúÍ∞ÅÌôî) ---")

    def load_new_grayscale_image(path, size=256):
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
        if img is None: return None
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize((size, size), antialias=True)
        ])
        return transform(img).float().unsqueeze(0).to(device)

    model.eval()

    if len(dataset) > 0:
        first_filename = dataset.filenames[0]
        test_grayscale_path = os.path.join(grayscale_dir, first_filename)
        test_input = load_new_grayscale_image(test_grayscale_path, image_size)

        if test_input is not None:
            with torch.no_grad():
                output_tensor = model(test_input)

            output_img = output_tensor.squeeze().cpu().permute(1, 2, 0).numpy()
            input_img = test_input.squeeze().cpu().numpy()

            output_img = np.clip(output_img, 0, 1)

            plt.figure(figsize=(10, 5))
            plt.subplot(1, 2, 1)
            plt.imshow(input_img, cmap='gray')
            plt.title("Grayscale Input")
            plt.axis('off')

            plt.subplot(1, 2, 2)
            plt.imshow(output_img)
            plt.title("Colorized Output")
            plt.axis('off')

            plt.show()


if __name__ == '__main__':
    COLOR_IMAGE_DIR = './color_images'
    GRAYSCALE_IMAGE_DIR = './grayscale_images'

    # Î™®Îç∏ ÌïôÏäµ Î∞è ÌÖåÏä§Ìä∏ Ïã§Ìñâ
    train_and_predict_colorization(COLOR_IMAGE_DIR, GRAYSCALE_IMAGE_DIR)