import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import cv2
import numpy as np
import os
import glob
from matplotlib import pyplot as plt
from tqdm import tqdm  # í•™ìŠµ ì§„í–‰ë¥ ì„ í‘œì‹œí•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€


# --- 0. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ í•„ìš”: tqdm ---
# í„°ë¯¸ë„ì—ì„œ 'pip install tqdm'ì„ ë¨¼ì € ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.

# --- 1. U-Net Architecture Definition (ëª¨ë¸ êµ¬ì¡°) ---
# (ì´ ë¶€ë¶„ì€ ì´ì „ê³¼ ë™ì¼í•˜ë©° ìƒëµí•©ë‹ˆë‹¤.)

class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(DoubleConv, self).__init__()
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.double_conv(x)


class UNet(nn.Module):
    def __init__(self, n_channels=1, n_classes=3):
        super(UNet, self).__init__()
        self.inc = DoubleConv(n_channels, 64)
        self.down1 = nn.MaxPool2d(2);
        self.conv1 = DoubleConv(64, 128)
        self.down2 = nn.MaxPool2d(2);
        self.conv2 = DoubleConv(128, 256)
        self.down3 = nn.MaxPool2d(2);
        self.conv3 = DoubleConv(256, 512)
        self.down4 = nn.MaxPool2d(2);
        self.conv4 = DoubleConv(512, 1024)

        self.up1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)
        self.up_conv1 = DoubleConv(1024, 512)
        self.up2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)
        self.up_conv2 = DoubleConv(512, 256)
        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.up_conv3 = DoubleConv(256, 128)
        self.up4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.up_conv4 = DoubleConv(128, 64)

        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.down1(x1);
        x2 = self.conv1(x2)
        x3 = self.down2(x2);
        x3 = self.conv2(x3)
        x4 = self.down3(x3);
        x4 = self.conv3(x4)
        x5 = self.down4(x4);
        x5 = self.conv4(x5)

        x = self.up1(x5);
        x = torch.cat([x, x4], dim=1);
        x = self.up_conv1(x)
        x = self.up2(x);
        x = torch.cat([x, x3], dim=1);
        x = self.up_conv2(x)
        x = self.up3(x);
        x = torch.cat([x, x2], dim=1);
        x = self.up_conv3(x)
        x = self.up4(x);
        x = torch.cat([x, x1], dim=1);
        x = self.up_conv4(x)

        return self.outc(x)


# --- 2. Custom Dataset Class ---
# (ì´ ë¶€ë¶„ì€ ì´ì „ê³¼ ë™ì¼í•©ë‹ˆë‹¤.)
class ColorizationDataset(Dataset):
    def __init__(self, color_dir, grayscale_dir, image_size=256):
        self.color_dir = color_dir
        self.grayscale_dir = grayscale_dir
        self.image_size = image_size

        self.filenames = [os.path.basename(f) for f in glob.glob(os.path.join(color_dir, '*.jpg'))]

        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize((image_size, image_size), antialias=True)
        ])

    def __len__(self):
        return len(self.filenames)

    def __getitem__(self, idx):
        filename = self.filenames[idx]

        grayscale_path = os.path.join(self.grayscale_dir, filename)
        input_img = cv2.imread(grayscale_path, cv2.IMREAD_GRAYSCALE)

        color_path = os.path.join(self.color_dir, filename)
        target_img = cv2.imread(color_path, cv2.IMREAD_COLOR)

        if input_img is None or target_img is None:
            raise RuntimeError(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨. íŒŒì¼ì´ ë‘ í´ë” ëª¨ë‘ì— ìˆëŠ”ì§€ í™•ì¸: {filename}")

        target_img = cv2.cvtColor(target_img, cv2.COLOR_BGR2RGB)

        input_tensor = self.transform(input_img).float()
        target_tensor = self.transform(target_img).float()

        return input_tensor, target_tensor


# --- 3. Training and Prediction Function (tqdm ì ìš©) ---

def train_and_predict_colorization(color_dir, grayscale_dir, model_save_path='./colorization_unet.pth'):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ì‚¬ìš© ì¥ì¹˜: {device}")

    # Hyperparameters
    num_epochs = 20
    learning_rate = 0.0005
    batch_size = 4
    image_size = 256

    # Data Loading
    print("\nğŸ“¦ ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
    dataset = ColorizationDataset(color_dir, grayscale_dir, image_size)

    if len(dataset) == 0:
        print("\nğŸš¨ ì˜¤ë¥˜: í•™ìŠµí•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ë‘ í´ë”ì— ì´ë¯¸ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return

    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
    num_batches = len(dataloader)

    # Model, Loss, Optimizer
    model = UNet(n_channels=1, n_classes=3).to(device)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    # --- Training Loop ---
    print(f"\n--- ëª¨ë¸ í•™ìŠµ ì‹œì‘ (ì´ ì´ë¯¸ì§€ ìˆ˜: {len(dataset)}, ì´ ë°°ì¹˜ ìˆ˜: {num_batches}) ---")
    model.train()

    for epoch in range(num_epochs):
        # tqdmì„ ì‚¬ìš©í•˜ì—¬ í˜„ì¬ Epochì˜ ì§„í–‰ ìƒí™©ì„ ë§‰ëŒ€ ê·¸ë˜í”„ë¡œ í‘œì‹œ
        # desc: ì§„í–‰ë¥  í‘œì‹œì¤„ì˜ ì œëª© ì„¤ì •
        progress_bar = tqdm(enumerate(dataloader), total=num_batches,
                            desc=f"Epoch {epoch + 1}/{num_epochs}", unit="batch")

        running_loss = 0.0

        for i, (inputs, targets) in progress_bar:
            inputs, targets = inputs.to(device), targets.to(device)

            outputs = model(inputs)
            loss = criterion(outputs, targets)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

            # ì§„í–‰ë¥  í‘œì‹œì¤„ì— í˜„ì¬ ë°°ì¹˜ ì†ì‹¤(Loss) ê°’ ì—…ë°ì´íŠ¸
            progress_bar.set_postfix({'Loss': loss.item()})

        avg_epoch_loss = running_loss / num_batches
        print(f"\n[Epoch {epoch + 1} ì™„ë£Œ] ğŸŒŸ í‰ê·  ì†ì‹¤(Avg Loss): {avg_epoch_loss:.6f}")

    print("âœ… í•™ìŠµ ì™„ë£Œ. ëª¨ë¸ ì €ì¥ ì¤‘...")
    torch.save(model.state_dict(), model_save_path)
    print(f"ëª¨ë¸ì´ '{model_save_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # --- Prediction Example (í…ŒìŠ¤íŠ¸ ë¶€ë¶„) ---
    print("\n--- í•™ìŠµëœ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ (ê²°ê³¼ ì‹œê°í™”) ---")

    def load_new_grayscale_image(path, size=256):
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
        if img is None: return None
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize((size, size), antialias=True)
        ])
        return transform(img).float().unsqueeze(0).to(device)

    model.eval()

    if len(dataset) > 0:
        first_filename = dataset.filenames[0]
        test_grayscale_path = os.path.join(grayscale_dir, first_filename)
        test_input = load_new_grayscale_image(test_grayscale_path, image_size)

        if test_input is not None:
            with torch.no_grad():
                output_tensor = model(test_input)

            output_img = output_tensor.squeeze().cpu().permute(1, 2, 0).numpy()
            input_img = test_input.squeeze().cpu().numpy()

            output_img = np.clip(output_img, 0, 1)

            plt.figure(figsize=(10, 5))
            plt.subplot(1, 2, 1)
            plt.imshow(input_img, cmap='gray')
            plt.title("Grayscale Input")
            plt.axis('off')

            plt.subplot(1, 2, 2)
            plt.imshow(output_img)
            plt.title("Colorized Output")
            plt.axis('off')

            plt.show()


if __name__ == '__main__':
    # í•™ìŠµì— ì‚¬ìš©í•  ë°ì´í„° í´ë” ê²½ë¡œ
    COLOR_IMAGE_DIR = './color_images'
    GRAYSCALE_IMAGE_DIR = './grayscale_images'

    # ëª¨ë¸ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    train_and_predict_colorization(COLOR_IMAGE_DIR, GRAYSCALE_IMAGE_DIR)